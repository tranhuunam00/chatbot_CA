import os
import requests
from dotenv import load_dotenv
import glob

from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings

# 1. Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise EnvironmentError("âŒ Thiáº¿u GOOGLE_API_KEY trong file .env")

# 2. Load táº¥t cáº£ tÃ i liá»‡u tá»« thÆ° má»¥c "data"
all_documents = []
file_paths = glob.glob("data/*.txt")
for path in file_paths:
    loader = TextLoader(path, encoding="utf-8")
    all_documents.extend(loader.load())
print(f"âœ… ÄÃ£ load {len(file_paths)} file vÄƒn báº£n")

# 3. Chia nhá» vÄƒn báº£n Ä‘á»ƒ index
splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=50)
chunks = splitter.split_documents(all_documents)
print(f"âœ… ÄÃ£ chia thÃ nh {len(chunks)} Ä‘oáº¡n")

# 4. Táº¡o embedding báº±ng Gemini
embedding = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

# 5. Táº¡o FAISS vector store
db = FAISS.from_documents(chunks, embedding)
print("âœ… ÄÃ£ táº¡o FAISS vector store thÃ nh cÃ´ng")

# 6. HÃ m gá»i Gemini API Ä‘á»ƒ sinh vÄƒn báº£n


def generate_from_prompt(prompt: str) -> str:
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}
    body = {
        "contents": [
            {
                "parts": [{"text": prompt}]
            }
        ]
    }
    try:
        response = requests.post(url, headers=headers, json=body)
        response.raise_for_status()
        result = response.json()
        text = result["candidates"][0]["content"]["parts"][0]["text"]
        return text
    except Exception as e:
        print("ğŸŒ Lá»—i káº¿t ná»‘i Gemini API:", e)
        return "âŒ Lá»—i khÃ´ng truy xuáº¥t Ä‘Æ°á»£c cÃ¢u tráº£ lá»i tá»« Gemini."

# 7. HÃ m táº¡o prompt tá»« cÃ¢u há»i vÃ  ná»™i dung tÃ i liá»‡u


def create_prompt(query: str, docs: list) -> str:
    data = "\n\n".join([doc.page_content for doc in docs])
    return f"""
Báº¡n lÃ  má»™t trá»£ lÃ½ áº£o Ä‘Æ°á»£c huáº¥n luyá»‡n chuyÃªn sÃ¢u vá» **Y há»c giáº¥c ngá»§** vÃ  cÃ¡c kiáº¿n thá»©c giáº£ng dáº¡y trong chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o 6 thÃ¡ng cá»§a **Há»™i Y há»c Giáº¥c ngá»§ Viá»‡t Nam**.

DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c thÃ´ng tin trÃ­ch xuáº¥t tá»« tÃ i liá»‡u chÃ­nh thá»©c:

{data}

HÃ£y sá»­ dá»¥ng cÃ¡c thÃ´ng tin trÃªn Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i sau báº±ng tiáº¿ng Viá»‡t, rÃµ rÃ ng, chÃ­nh xÃ¡c vÃ  cÃ³ cÄƒn cá»© khoa há»c:
"{query}"

âš ï¸ YÃªu cáº§u:
- Tráº£ lá»i Ä‘Ãºng ná»™i dung chuyÃªn ngÃ nh y há»c giáº¥c ngá»§, Ä‘áº·c biá»‡t cÃ¡c chá»§ Ä‘á» nhÆ°: sinh lÃ½ há»c giáº¥c ngá»§, cÃ¡c rá»‘i loáº¡n giáº¥c ngá»§, ká»¹ thuáº­t cháº©n Ä‘oÃ¡n, Ä‘iá»u trá»‹ báº±ng CPAP, ká»¹ nÄƒng thá»±c hÃ nh lÃ¢m sÃ ng, Ä‘Ã¡nh giÃ¡ Ä‘áº§u ra, cáº¥u trÃºc khÃ³a há»c, v.v.
- Náº¿u khÃ´ng Ä‘á»§ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i, hÃ£y nÃªu rÃµ Ä‘iá»u Ä‘Ã³ má»™t cÃ¡ch lá»‹ch sá»± vÃ  trung thá»±c.
- Tráº£ lá»i cÃ³ cáº¥u trÃºc, rÃµ rÃ ng, dá»… hiá»ƒu, Ä‘Ãºng vá»›i chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o vÃ  thuáº­t ngá»¯ chuyÃªn ngÃ nh.
"""


# 8. Demo truy váº¥n thá»­
query = "Tá»•ng sá»‘ tiáº¿t thá»±c hÃ nh trong chÆ°Æ¡ng trÃ¬nh lÃ  bao nhiÃªu?"
docs = db.similarity_search(query, k=3)
prompt = create_prompt(query, docs)
response = generate_from_prompt(prompt)

print("\nğŸ¤– CÃ¢u tráº£ lá»i tá»« Gemini:")
print(response)
