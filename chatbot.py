import os
import requests
from dotenv import load_dotenv
import glob

from langchain_community.document_loaders import TextLoader
from langchain_community.vectorstores import FAISS
from langchain.text_splitter import CharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings

# 1. Load biáº¿n mÃ´i trÆ°á»ng
load_dotenv()
api_key = os.getenv("GOOGLE_API_KEY")
if not api_key:
    raise EnvironmentError("âŒ Thiáº¿u GOOGLE_API_KEY trong file .env")

# 2. Load táº¥t cáº£ tÃ i liá»‡u tá»« folder "data"
all_documents = []
file_paths = glob.glob("data/*.txt")
for path in file_paths:
    loader = TextLoader(path, encoding="utf-8")
    all_documents.extend(loader.load())
print(f"âœ… ÄÃ£ load {len(file_paths)} file vÄƒn báº£n")

# 3. Chia nhá» vÄƒn báº£n Ä‘á»ƒ index
splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=50)
chunks = splitter.split_documents(all_documents)
print(f"âœ… ÄÃ£ chia thÃ nh {len(chunks)} Ä‘oáº¡n")

# 4. Táº¡o embedding báº±ng Gemini
embedding = GoogleGenerativeAIEmbeddings(model="models/embedding-001")

# 5. Táº¡o FAISS vector store
db = FAISS.from_documents(chunks, embedding)
print("âœ… ÄÃ£ táº¡o FAISS vector store thÃ nh cÃ´ng")

# 6. HÃ m gá»i Gemini API sinh vÄƒn báº£n (dÃ¹ng gemini-2.0-flash)


def generate_from_prompt(prompt: str) -> str:
    url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}"
    headers = {"Content-Type": "application/json"}
    body = {
        "contents": [
            {
                "parts": [{"text": prompt}]
            }
        ]
    }
    try:
        response = requests.post(url, headers=headers, json=body)
        response.raise_for_status()
        result = response.json()
        text = result["candidates"][0]["content"]["parts"][0]["text"]
        return text
    except Exception as e:
        print("ğŸŒ Lá»—i káº¿t ná»‘i Gemini API:", e)
        return "âŒ Lá»—i khÃ´ng truy xuáº¥t Ä‘Æ°á»£c cÃ¢u tráº£ lá»i tá»« Gemini."

# 7. HÃ m táº¡o prompt tá»« cÃ¢u há»i vÃ  dá»¯ liá»‡u truy váº¥n


def create_prompt(query: str, docs: list) -> str:
    data = "\n\n".join([doc.page_content for doc in docs])
    return f"""
Báº¡n lÃ  má»™t trá»£ lÃ½ áº£o Ä‘Æ°á»£c huáº¥n luyá»‡n chuyÃªn sÃ¢u vá» **thá»§ tá»¥c hÃ nh chÃ­nh vÃ  cÃ¡c quy Ä‘á»‹nh phÃ¡p luáº­t trong lÄ©nh vá»±c CÃ´ng an** Viá»‡t Nam.
DÆ°á»›i Ä‘Ã¢y lÃ  cÃ¡c thÃ´ng tin Ä‘Ã£ Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« tÃ i liá»‡u chÃ­nh thá»©c (vÄƒn báº£n phÃ¡p luáº­t, hÆ°á»›ng dáº«n tá»« Bá»™ CÃ´ng an):

{data}

HÃ£y sá»­ dá»¥ng cÃ¡c thÃ´ng tin trÃªn Ä‘á»ƒ tráº£ lá»i cho cÃ¢u há»i sau báº±ng tiáº¿ng Viá»‡t, rÃµ rÃ ng, chÃ­nh xÃ¡c vÃ  cÃ³ cÄƒn cá»© phÃ¡p lÃ½:
"{query}"

âš ï¸ YÃªu cáº§u:
- Æ¯u tiÃªn cÃ¡c ná»™i dung liÃªn quan Ä‘áº¿n thá»§ tá»¥c hÃ nh chÃ­nh (há»™ kháº©u, CCCD, cÆ° trÃº, xá»­ pháº¡t hÃ nh chÃ­nh, xuáº¥t nháº­p cáº£nh, Ä‘Äƒng kÃ½ phÆ°Æ¡ng tiá»‡n, v.v.).
- Náº¿u cÃ¢u há»i liÃªn quan Ä‘áº¿n hÃ¬nh sá»±, quy Ä‘á»‹nh phÃ¡p luáº­t, hÃ nh vi vi pháº¡m,... váº«n cÃ³ thá»ƒ tráº£ lá»i náº¿u náº±m trong pháº¡m vi cÃ¡c tÃ i liá»‡u Ä‘Ã£ cung cáº¥p.
- Náº¿u khÃ´ng Ä‘á»§ thÃ´ng tin Ä‘á»ƒ tráº£ lá»i, hÃ£y nÃ³i rÃµ Ä‘iá»u Ä‘Ã³ má»™t cÃ¡ch lá»‹ch sá»± vÃ  trung thá»±c.
- Tráº£ lá»i cÃ³ cáº¥u trÃºc, chÃ­nh xÃ¡c, Ä‘Ãºng quy Ä‘á»‹nh, cÃ³ thá»ƒ nÃªu cÃ¡c bÆ°á»›c, há»“ sÆ¡, má»©c pháº¡t hoáº·c Ä‘iá»u khoáº£n phÃ¡p luáº­t tÆ°Æ¡ng á»©ng.
"""


# 8. Demo truy váº¥n
query = "ThÃ´ng tin trÃªn giáº¥y tá» xuáº¥t nháº­p cáº£nh bao gá»“m"
docs = db.similarity_search(query, k=3)
prompt = create_prompt(query, docs)
response = generate_from_prompt(prompt)

print("\nğŸ¤– CÃ¢u tráº£ lá»i tá»« Gemini:")
print(response)
